{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHANDAN KUMAR TIME SERIES 3 FB PROPHET  .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41dtqtCDwY6_"
      },
      "source": [
        "#CHANDAN KUMAR (BATCH 3)- GOOGLE COLAB / TIME SERIES 3 : Fb PropHet\n",
        "##(Rahul Agnihotri(T.L))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlFeMSmtv0s3"
      },
      "source": [
        "#DataSet - [Rossmann DataSet](https://drive.google.com/drive/folders/19JV-Ll2WjLHfe-d8zI1i8G6_jbxzTd-E?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtSeOxRrOoAo"
      },
      "source": [
        "#Fb PropHet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtkU5-7YNnUN"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbEtnXpEvyVO"
      },
      "source": [
        "!python -m pip install --upgrade pip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWC_4RZvN_58"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import datetime\n",
        "\n",
        "# data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "%matplotlib inline\n",
        "\n",
        "# statistics\n",
        "from statsmodels.distributions.empirical_distribution import ECDF\n",
        "\n",
        "# time series analysis\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# prophet by Facebook\n",
        "from fbprophet import Prophet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzYxejMDP1OR"
      },
      "source": [
        "# Importing DataSets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHMJf4B7PEQj"
      },
      "source": [
        "# importing train data to learn\n",
        "train_df = pd.read_csv(\"/content/train.csv\", \n",
        "                    parse_dates = True, low_memory = False, index_col = 'Date')\n",
        "\n",
        "# additional store data\n",
        "store_df = pd.read_csv(\"/content/store.csv\", \n",
        "                    low_memory = False)\n",
        "print('Time Series :\\n',train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrE_7NsyQMT5"
      },
      "source": [
        "#Exploratory Data Analysis(EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a72Jsk20RUkB"
      },
      "source": [
        "print(\"_________E D A * I N F 0________\\n\")\n",
        "print('/   INFO  /\\n',train_df.info(),' | ',store_df.info())\n",
        "print('SHAPE : \\n','1. TRAIN',train_df.shape,'\\n 2. STORE',store_df.shape)\n",
        "print('HEAD : \\n','1. TRAIN',train_df.head(5),'\\n 2. STORE',store_df.head(5))\n",
        "#print('NULL : \\n','STORE :'.store_df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn1AIRHie4kc"
      },
      "source": [
        "- Store: a unique Id for each store\n",
        "- StoreType: differentiates between 4 different store models: a, b, c, d\n",
        "- Assortment: describes an assortment level: a = basic, b = extra, c = extended\n",
        "- CompetitionDistance: distance in meters to the nearest competitor store\n",
        "- CompetitionOpenSince[Month/Year]: gives the approximate year and month of the time the nearest competitor was opened\n",
        "- Promo2: Promo2 is a continuing a promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "- Promo2Since[Year/Week]: describes the year and calendar week when the store started participating in Promo2\n",
        "- PromoInterval: describes the consecutive intervals Promo2 is started, naming the months the promotion is started. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2ZDYEXxV2Fl"
      },
      "source": [
        "# data extraction\n",
        "train_df['Year'] = train_df.index.year\n",
        "train_df['Month'] = train_df.index.month\n",
        "train_df['Day'] = train_df.index.day\n",
        "train_df['WeekOfYear'] = train_df.index.weekofyear\n",
        "\n",
        "# adding new variable\n",
        "train_df['SalePerCustomer'] = train_df['Sales']/train_df['Customers']\n",
        "train_df['SalePerCustomer'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQZ_BPmsbzKi"
      },
      "source": [
        "#ECDF: empirical cumulative distribution function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DprJnqlFcFK_"
      },
      "source": [
        "An ECDF is an estimator of the Cumulative Distribution Function. The ECDF essentially allows you to plot a feature of your data in order from least to greatest and see the whole feature as if is distributed across the data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62ZZn8QScSZi"
      },
      "source": [
        " Continious variables in the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RreLdjAcbxlc"
      },
      "source": [
        "sns.set(style = \"ticks\")# to format into seaborn \n",
        "c = '#386B7F' # basic color for plots\n",
        "plt.figure(figsize = (12, 6))\n",
        "\n",
        "\"\"\"\n",
        "subplot(nrows, ncols, index, **kwargs)\n",
        "subplot(pos, **kwargs)\n",
        "subplot(ax)\n",
        "\"\"\"\n",
        "plt.subplot(311)\n",
        "cdf = ECDF(train_df['Sales'])\n",
        "plt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\n",
        "plt.xlabel('Sales'); plt.ylabel('ECDF');\n",
        "\n",
        "# plot second ECDF  \n",
        "plt.subplot(312)\n",
        "cdf = ECDF(train_df['Customers'])\n",
        "plt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\n",
        "plt.xlabel('Customers');\n",
        "\n",
        "# plot second ECDF  \n",
        "plt.subplot(313)\n",
        "cdf = ECDF(train_df['SalePerCustomer'])\n",
        "plt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\n",
        "plt.xlabel('Sale per Customer');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwChS2JkcwjP"
      },
      "source": [
        "About 20% of data has zero amount of sales / customers that we need to deal with and almost 80% of time daily amount of sales was less than 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s7rkbaxdGDh"
      },
      "source": [
        "(*) zero sales, is it only due to the fact that the store is closed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AnTU9Vmc32O"
      },
      "source": [
        "# Working on  Missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLKjSuWYc3bY"
      },
      "source": [
        "# closed stores\n",
        "train_df[(train_df.Open == 0) & (train_df.Sales == 0)].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7wAf4-CcyF5"
      },
      "source": [
        "# opened stores with zero sales\n",
        "zero_sales = train_df[(train_df.Open != 0) & (train_df.Sales == 0)]\n",
        "print(\"In total: \", zero_sales.shape)\n",
        "zero_sales.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_iVGPbFenx-"
      },
      "source": [
        "Interestingly enough, there are opened store with no sales on working days. There're only 54 days in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2utAjSWeogR"
      },
      "source": [
        "print(\"Closed stores and days which didn't have any sales won't be counted into the forecasts.\")\n",
        "train_df = train_df[(train_df[\"Open\"] != 0) & (train_df['Sales'] != 0)]\n",
        "\n",
        "print(\"In total: \", train_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfmh-V9bfBVs"
      },
      "source": [
        "#STORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ife_aRoXe_vP"
      },
      "source": [
        "# missing values?\n",
        "store_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHRQIGVkf6h7"
      },
      "source": [
        "# missing values in CompetitionDistance\n",
        "store[pd.isnull(store_df.CompetitionDistance)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQlPvOvwgI-b"
      },
      "source": [
        "#replace NaN with the median values (which is twice less that the average).\n",
        "store_df['CompetitionDistance'].fillna(store_df['CompetitionDistance'].median(), inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZYBvT3XggEN"
      },
      "source": [
        "We are going to replace NaN vlaues in\n",
        "\n",
        "1. Promo2SinceWeek             544\n",
        "\n",
        "\n",
        "with 0, becoz there's no information about it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFfDOsOCg0ln"
      },
      "source": [
        "# no promo = no information about the promo?\n",
        "_ = store[pd.isnull(store.Promo2SinceWeek)]\n",
        "_[_.Promo2 != 0].shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLYmdZcbhHis"
      },
      "source": [
        "# replace NA's by 0\n",
        "store.fillna(0, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG0e0u3Jhq9y"
      },
      "source": [
        "##JOINING TRAIN WITH STORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjDwYsEthIP6"
      },
      "source": [
        "print(\"Joining train set with an additional store information.\")\n",
        "\n",
        "# by specifying inner join we make sure that only those observations \n",
        "# that are present in both train and store sets are merged together\n",
        "train_store = pd.merge(train_df, store_df, how = 'inner', on = 'Store')\n",
        "\n",
        "print(\"In total: \", train_store.shape)\n",
        "train_store.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmqruXSEiAPY"
      },
      "source": [
        "##Store types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bliNZFUSiBug"
      },
      "source": [
        "train_store.groupby('StoreType')['Sales'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vol2RfA0kPaM"
      },
      "source": [
        "##overall sum of Sales and Customers to see which StoreType is the most selling and crowded one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2JswFG1iEBY"
      },
      "source": [
        "train_store.groupby('StoreType')['Customers', 'Sales'].sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMFCjeieklrJ"
      },
      "source": [
        "Clearly stores of type A. \n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "`StoreType` D goes on the second place in both `Sales` and `Customers`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkeBgkoGksoq"
      },
      "source": [
        "#Seaborn's facet grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK-A0sfnkvce"
      },
      "source": [
        "###for date periods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuU0qFu4kvEX"
      },
      "source": [
        "# sales trends\n",
        "sns.factorplot(data = train_store, x = 'Month', y = \"Sales\", \n",
        "               col = 'StoreType', # per store type in cols\n",
        "               palette = 'plasma',\n",
        "               hue = 'StoreType',\n",
        "               row = 'Promo', # per promo in the store in rows\n",
        "               color = c)\n",
        "\n",
        "sns.factorplot(data = train_store, x = 'Month', y = \"Customers\", \n",
        "               col = 'StoreType', # per store type in cols\n",
        "               palette = 'plasma',\n",
        "               hue = 'StoreType',\n",
        "               row = 'Promo', # per promo in the store in rows\n",
        "               color = c) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5bkUQ_aldU4"
      },
      "source": [
        "All store types follow the same trend but at different scales depending on the presence of the (first) promotion Promo and StoreType itself (case for B)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPQcFq9KkmgM"
      },
      "source": [
        "# sale per customer trends\n",
        "sns.factorplot(data = train_store, x = 'Month', y = \"SalePerCustomer\", \n",
        "               col = 'StoreType', # per store type in cols\n",
        "               palette = 'plasma',\n",
        "               hue = 'StoreType',\n",
        "               row = 'Promo', # per promo in the store in rows\n",
        "               color = c) \n",
        "\n",
        "# customers\n",
        "sns.factorplot(data = train_store, x = 'Month', y = \"Sales\", \n",
        "               col = 'DayOfWeek', # per store type in cols\n",
        "               palette = 'plasma',\n",
        "               hue = 'StoreType',\n",
        "               row = 'StoreType', # per store type in rows\n",
        "               color = c) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVrCb73Ol3nM"
      },
      "source": [
        "Low SalePerCustomer amount for StoreType B describes its Buyer Cart: there are a lot of people who shop essentially for \"small\" things (or in a little quantity). Plus we saw that overall this StoreType generated the least amount of sales and customers over the period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1cMfZR9mHGR"
      },
      "source": [
        "#By the way what are the stores which are opened on Sundays?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0Q7DjV3l3X1"
      },
      "source": [
        "# stores which are opened on Sundays\n",
        "train_store[(train_store.Open == 1) & (train_store.DayOfWeek == 7)]['Store'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKGkNdapnwXX"
      },
      "source": [
        "#To complete our preliminary data analysis, we can add variables describing the period of time during which competition and promotion were opened:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEmQhctnnx_g"
      },
      "source": [
        "# competition open time (in months)\n",
        "train_store['CompetitionOpen'] = 12 * (train_store.Year - train_store.CompetitionOpenSinceYear) + \\\n",
        "        (train_store.Month - train_store.CompetitionOpenSinceMonth)\n",
        "    \n",
        "# Promo open time\n",
        "train_store['PromoOpen'] = 12 * (train_store.Year - train_store.Promo2SinceYear) + \\\n",
        "        (train_store.WeekOfYear - train_store.Promo2SinceWeek) / 4.0\n",
        "\n",
        "# replace NA's by 0\n",
        "train_store.fillna(0, inplace = True)\n",
        "\n",
        "# average PromoOpen time and CompetitionOpen time per store type\n",
        "train_store.loc[:, ['StoreType', 'Sales', 'Customers', 'PromoOpen', 'CompetitionOpen']].groupby('StoreType').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9efq0gyn8Ma"
      },
      "source": [
        "The most selling and crowded StoreType A doesn't appear to be the one the most exposed to competitors. Instead it's a StoreType B, which also has the longest running period of promotion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJX_DE69n9Nd"
      },
      "source": [
        "#Correlational Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x716wS6koG6G"
      },
      "source": [
        "##check the overall correlations by plotting the seaborn heatmap:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l84JpqSnoAj3"
      },
      "source": [
        "# Compute the correlation matrix \n",
        "# exclude 'Open' variable\n",
        "corr_all = train_store.drop('Open', axis = 1).corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr_all, dtype = np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize = (11, 9))\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr_all, mask = mask,\n",
        "            square = True, linewidths = .5, ax = ax, cmap = \"YlOrBr\")      \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND7akrxnowia"
      },
      "source": [
        "A strong positive correlation between the amount of Sales and Customers of a store. We can also observe a positive correlation between the fact that the store had a running promotion (Promo equal to 1) and amount of Customers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h9uptCeozMC"
      },
      "source": [
        "# sale per customer trends\n",
        "sns.factorplot(data = train_store, x = 'DayOfWeek', y = \"Sales\", \n",
        "               col = 'Promo', \n",
        "               row = 'Promo2',\n",
        "               hue = 'Promo2',\n",
        "               palette = 'RdPu') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL4Pc6BDpA53"
      },
      "source": [
        "In case of no promotion, both Promo and Promo2 are equal to 0, Sales tend to peak on Sunday (!). Though we should note that StoreType C doesn't work on Sundays. So it is mainly data from StoreType A, B and D."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWeJcjulpBvM"
      },
      "source": [
        "Stores that run the promotion tend to make most of the Sales on Monday. This fact could be a good indicator for Rossmann marketing campaigns. The same trend follow the stores which have both promotion at the same time (Promo and Promo2 are equal to 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H_5zNmMpE-3"
      },
      "source": [
        "Promo2 alone doesn't seem to be correlated to any significant change in the Sales amount. This can be also prooved by the blue pale area on the heatmap above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEVLAJdxpHvC"
      },
      "source": [
        "#Conclusion of EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtb7eCmDporq"
      },
      "source": [
        "A time series analysis on store types instead of individual stores. The main advantage of this approach is its simplicity of presentation and overall account for different trends and seasonalities in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfCmBfyYpvtA"
      },
      "source": [
        "#Seasonality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6PY8rdTp7vc"
      },
      "source": [
        "##### We take four stores from store types to represent their group:\n",
        "- Store number 2 for `StoreType` A\n",
        "- Store number 85 for `StoreType` B, \n",
        "- Store number 1 for `StoreType` C \n",
        "- Store number 13 for `StoreType` D. \n",
        "\n",
        "It also makes sense to downsample the data from days to weeks using the `resample` method to see the present trends more clearly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFQzfm08psJT"
      },
      "source": [
        "# preparation: input should be float type\n",
        "train_df['Sales'] = train_df['Sales'] * 1.0\n",
        "\n",
        "# store types\n",
        "sales_a = train_df[train.Store == 2]['Sales']\n",
        "sales_b = train_df[train.Store == 85]['Sales'].sort_index(ascending = True) # solve the reverse order\n",
        "sales_c = train_df[train.Store == 1]['Sales']\n",
        "sales_d = train_df[train.Store == 13]['Sales']\n",
        "\n",
        "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize = (12, 13))\n",
        "\n",
        "# store types\n",
        "sales_a.resample('W').sum().plot(color = c, ax = ax1)\n",
        "sales_b.resample('W').sum().plot(color = c, ax = ax2)\n",
        "sales_c.resample('W').sum().plot(color = c, ax = ax3)\n",
        "sales_d.resample('W').sum().plot(color = c, ax = ax4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpwJ0p_4q22z"
      },
      "source": [
        "\"\"\"Retail sales for StoreType A and C \n",
        "tend to peak for the Christmas season and then decline after \n",
        "the holidays. We might have seen the same trend \n",
        "for \n",
        "StoreType D (at the bottom) \n",
        "but there is no information \n",
        "from July 2014 to January 2015 about \n",
        "these stores as they were closed.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA-N86vHrBeQ"
      },
      "source": [
        "#Yearly trend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDJIqHvErMcc"
      },
      "source": [
        "##Seasonal Decompose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YCZ2KLfrEh5"
      },
      "source": [
        "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize = (12, 13))\n",
        "\n",
        "# monthly\n",
        "decomposition_a = seasonal_decompose(sales_a, model = 'additive', freq = 365)\n",
        "decomposition_a.trend.plot(color = c, ax = ax1)\n",
        "\n",
        "decomposition_b = seasonal_decompose(sales_b, model = 'additive', freq = 365)\n",
        "decomposition_b.trend.plot(color = c, ax = ax2)\n",
        "\n",
        "decomposition_c = seasonal_decompose(sales_c, model = 'additive', freq = 365)\n",
        "decomposition_c.trend.plot(color = c, ax = ax3)\n",
        "\n",
        "decomposition_d = seasonal_decompose(sales_d, model = 'additive', freq = 365)\n",
        "decomposition_d.trend.plot(color = c, ax = ax4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSwZFB20rT7r"
      },
      "source": [
        "Overall sales seems to increase, however not for the StoreType C (a third from the top). Eventhough the StoreType A is the most selling store type in the dataset, it seems that it cab follow the same decresing trajectory as StoreType C did."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpAqm2SPrW08"
      },
      "source": [
        "#Autocorrelaion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZkCAC1NrY1l"
      },
      "source": [
        "The next step in ourtime series analysis is to review Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YU7uuW0ra55"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl7cPpyqrfzJ"
      },
      "source": [
        "# figure for subplots\n",
        "plt.figure(figsize = (12, 8))\n",
        "\n",
        "# acf and pacf for A\n",
        "plt.subplot(421); plot_acf(sales_a, lags = 50, ax = plt.gca(), color = c)\n",
        "plt.subplot(422); plot_pacf(sales_a, lags = 50, ax = plt.gca(), color = c)\n",
        "\n",
        "# acf and pacf for B\n",
        "plt.subplot(423); plot_acf(sales_b, lags = 50, ax = plt.gca(), color = c)\n",
        "plt.subplot(424); plot_pacf(sales_b, lags = 50, ax = plt.gca(), color = c)\n",
        "\n",
        "# acf and pacf for C\n",
        "plt.subplot(425); plot_acf(sales_c, lags = 50, ax = plt.gca(), color = c)\n",
        "plt.subplot(426); plot_pacf(sales_c, lags = 50, ax = plt.gca(), color = c)\n",
        "\n",
        "# acf and pacf for D\n",
        "plt.subplot(427); plot_acf(sales_d, lags = 50, ax = plt.gca(), color = c)\n",
        "plt.subplot(428); plot_pacf(sales_d, lags = 50, ax = plt.gca(), color = c)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeyNcXXirwnc"
      },
      "source": [
        "There is at two things common for each pair of plots: non randomnes of the time series and high lag-1 (which will probably need a higher order of differencing d/D).\n",
        "\n",
        "- Type A and type B: Both types show seasonalities at certain lags. For type A, it is each 12th observation with positives spikes at the 12 (s) and 24(2s) lags and so on. \n",
        "- For type B it's a weekly trend with positives spikes at the 7(s), 14(2s), 21(3s) and 28(4s) lags.\n",
        "- Type C and type D: Plots of these two types are more complex. It seems like each observation is coorrelated to its adjacent observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfvl31XDr2AE"
      },
      "source": [
        "#PropHet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXFAZ-mLr6Dq"
      },
      "source": [
        "next 6 weeks for the first store"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elhRVcrnsByh"
      },
      "source": [
        "# importing data\n",
        "df = pd.read_csv(\"../input/train.csv\",  \n",
        "                    low_memory = False)\n",
        "\n",
        "# remove closed stores and those with no sales\n",
        "df = df[(df[\"Open\"] != 0) & (df['Sales'] != 0)]\n",
        "\n",
        "# sales for the store number 1 (StoreType C)\n",
        "sales = df[df.Store == 1].loc[:, ['Date', 'Sales']]\n",
        "\n",
        "# reverse to the order: from 2013 to 2015\n",
        "sales = sales.sort_index(ascending = False)\n",
        "\n",
        "# to datetime64\n",
        "sales['Date'] = pd.DatetimeIndex(sales['Date'])\n",
        "sales.dtypes\n",
        "\n",
        "# from the prophet documentation every variables should have specific names\n",
        "sales = sales.rename(columns = {'Date': 'ds',\n",
        "                                'Sales': 'y'})\n",
        "sales.head()\n",
        "\n",
        "# plot daily sales\n",
        "ax = sales.set_index('ds').plot(figsize = (12, 4), color = c)\n",
        "ax.set_ylabel('Daily Number of Sales')\n",
        "ax.set_xlabel('Date')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88mrfPpdsTSw"
      },
      "source": [
        "#Facebook Forecasting at Scale\n",
        "[Facebook Forecasting at Scale](https://facebook.github.io/prophet/) - \n",
        "##StateHoliday"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6Djz7J8sl80"
      },
      "source": [
        "Prophet also allows to model for holidays, and that's what we do here.\n",
        "\n",
        "The StateHoliday variable in the dataset indicates a state holiday, at which all stores are normally closed. There are also school holidays in the dataset at which ceratin stores are also closing their doors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0ZSB0z_sp2z"
      },
      "source": [
        "# create holidays dataframe\n",
        "state_dates = df[(df.StateHoliday == 'a') | (df.StateHoliday == 'b') & (df.StateHoliday == 'c')].loc[:, 'Date'].values\n",
        "school_dates = df[df.SchoolHoliday == 1].loc[:, 'Date'].values\n",
        "\n",
        "state = pd.DataFrame({'holiday': 'state_holiday',\n",
        "                      'ds': pd.to_datetime(state_dates)})\n",
        "school = pd.DataFrame({'holiday': 'school_holiday',\n",
        "                      'ds': pd.to_datetime(school_dates)})\n",
        "\n",
        "holidays = pd.concat((state, school))      \n",
        "holidays.head()\n",
        "\n",
        "# set the uncertainty interval to 95% (the Prophet default is 80%)\n",
        "my_model = Prophet(interval_width = 0.95, \n",
        "                   holidays = holidays)\n",
        "my_model.fit(sales)\n",
        "\n",
        "# dataframe that extends into future 6 weeks \n",
        "future_dates = my_model.make_future_dataframe(periods = 6*7)\n",
        "\n",
        "print(\"First week to forecast.\")\n",
        "future_dates.tail(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgRkEvChs7MP"
      },
      "source": [
        "#Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EfYxazgs1rs"
      },
      "source": [
        "# predictions\n",
        "forecast = my_model.predict(future_dates)\n",
        "\n",
        "# preditions for last week\n",
        "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdmqA7hYs_hl"
      },
      "source": [
        "The forecast object here is a new dataframe that includes a column yhat with the forecast, as well as columns for components and uncertainty intervals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E15Mio3Zs_NR"
      },
      "source": [
        "fc = forecast[['ds', 'yhat']].rename(columns = {'Date': 'ds', 'Forecast': 'yhat'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKqTbQtktDNr"
      },
      "source": [
        "# visualizing predicions\n",
        "my_model.plot(forecast);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V78qnK1ItcL7"
      },
      "source": [
        "#As we see Prophet catches the trends and most of the time gets future values right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_n1efM9tbvt"
      },
      "source": [
        "my_model.plot_components(forecast);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeI3iAxFtpP1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvZGtQgAuJ1R"
      },
      "source": [
        "#Conclusion of Time Series forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fFYUWQCt7fL"
      },
      "source": [
        "- Advantages\n",
        "\n",
        "A powerful tool for the time series forecasting as it accounts for time dependencies, seasonalities and holidays (Prophet: manually).\n",
        "Easily implemented withaut o.arima() from forecast package, which runs a complex grid search and sophisticated algorithm behind the scene.\n",
        "\n",
        "- Drawbacks\n",
        "\n",
        "Doesn't catch interactions between external features, which could improve the forecasting power of a model. In our case, these variables are Promo and CompetitionOpen.\n",
        "Even though Prophet offers an automated solution for ARIMA, this methodology is under development and not completely stable.\n",
        "Fitting seasonal ARIMA model needs 4 to 5 whole seasons in the dataset, which can be the biggest drawback for new companies.\n",
        "Seasonal ARIMA in Python has 7 hyper parameters which can be tuned only manually affecting significantly the speed of the forecasting process."
      ]
    }
  ]
}